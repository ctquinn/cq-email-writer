{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"cq-email-writer\", name=\"fine_tuning_bart\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Paths and Model Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relative paths\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"src/gcloud/fine_tune_sentence_completion.json\")\n",
    "OUTPUT_DIR = os.path.join(\n",
    "    PROJECT_ROOT, \"src/transformers/fine_tuned_model_sentence_completion\"\n",
    ")\n",
    "MODEL_NAME = \"t5-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    \"\"\"Load the dataset from JSON.\"\"\"\n",
    "    with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return Dataset.from_list(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_data(examples, tokenizer, max_input_length=512, max_output_length=128):\n",
    "    \"\"\"\n",
    "    Tokenize the dataset.\n",
    "    - Inputs: Subject + Text so far\n",
    "    - Outputs: Next words\n",
    "    \"\"\"\n",
    "    inputs = examples[\"input\"]  # Extract the 'input' field from the batch\n",
    "    outputs = examples[\"output\"]  # Extract the 'output' field from the batch\n",
    "    model_inputs = tokenizer(\n",
    "        inputs,\n",
    "        max_length=max_input_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        outputs,\n",
    "        max_length=max_output_length,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "print(f\"Loading dataset from {DATA_PATH}...\")\n",
    "dataset = load_data(DATA_PATH)\n",
    "print(f\"Loaded {len(dataset)} examples.\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "print(f\"Loading model and tokenizer ({MODEL_NAME})...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize dataset\n",
    "print(\"Tokenizing dataset...\")\n",
    "tokenized_dataset = dataset.map(\n",
    "    lambda examples: tokenize_data(examples, tokenizer),\n",
    "    batched=True,\n",
    "    remove_columns=[\"input\", \"output\"],\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Setting up training arguments...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=os.path.join(OUTPUT_DIR, \"logs\"),\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    fp16=True if torch.cuda.is_available() else False,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"wandb\",  # Enable W&B logging\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize and Run Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing Trainer...\")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Starting fine-tuning...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving model to {OUTPUT_DIR}...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(\"Model saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
